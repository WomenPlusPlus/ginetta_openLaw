# AI Swiss Legal Assistant üá®üá≠ üë©‚Äç‚öñÔ∏è ü§ñ

This is a simple conversational-ui RAG (retrieval augmented generation) based on the Swiss Code of Obligations.

> It was created a starting point of the Ginetta Challenge at the women++ [Hack'n'Lead hackathon](www.womenplusplus.ch/hackandlead) November 2023

## ‚ñ∂Ô∏è How to Use

Execute [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app) with [npm](https://docs.npmjs.com/cli/init), [Yarn](https://yarnpkg.com/lang/en/docs/cli/create/), or [pnpm](https://pnpm.io) to bootstrap the example:

```bash
yarn create next-app --example https://github.com/ginetta/swiss-legal-conversational-ui
```


There is two different ways to setup this project:

1. Install Ollama & Qdrant locally _(Ollama desktop app is currently is only available for Mac and Linux)_ - Ollama will take advantage of your GPU to run the model
1. Use the [Docker Compose](https://docs.docker.com/compose/) file to run Ollama & Qdrant in containers (just run  in a terminal in the project directory) - easier setup, but Ollama will run on CPU

## üê≥ Setup & Run Docker Compose

1. `docker compose up -d` to pull & run the containers
1. `docker compose exec ollama ollama run mistral` to download & install the mistral model

## ü¶ô Run Ollama

1. [Download Ollama](https://ollama.ai/download) and install it locally
2. `ollama run mistral` to download and install the model locally (Requires 4.1GB and 8GB of RAM)
3. Open <http://localhost:11434> to check if _Ollama is running_

## üíæ Setup Qdrant Vector Database

1. `docker pull qdrant/qdrant`
1. `docker run -p 6333:6333 qdrant/qdrant`
1. Open the Qdrant dashboard console  <http://localhost:6333/dashboard#/console>
1. Create a new collection running this:
    ```curl
    PUT collections/swiss-or
    {
      "vectors": {
        "size": 384,
        "distance": "Cosine"
      }
    }
    ```
1. Download the [snapshot file](https://huggingface.co/datasets/brunnolou/swiss-code-of-obligations/resolve/main/swiss-code-of-obligations-articles-gte-small-2023-10-18-12-13-25_qdrant-v1-6-1.snapshot.zip)
1. Unzip the file using the terminal (‚ö†Ô∏è **_not with Finder on Mac_** ‚ö†Ô∏è) with `unzip swiss-code-of-obligations-articles-gte-small-2023-10-18-12-13-25_qdrant-v1-6-1.snapshot.zip`
1. Upload the file using the following command. Adapt the fields accordingly and run it from the same directory, as where your snapshot lies

```shell
curl -X POST 'http://localhost:6333/collections/swiss-or/snapshots/upload' \
    -H 'Content-Type:multipart/form-data' \
    -F 'snapshot=@swiss-code-of-obligations-articles-gte-small-2023-10-18-12-13-25.snapshot'
```

## üë©üèΩ‚Äçüíª Run the App

1. `yarn install` to install the required dependencies
1. Copy the file `.env.local.example` in the project and rename it to `.env`. Verify if all environment variables are correct
1. `yarn dev` to launch the development server
1. Go to <http://localhost:3000> and try out the app

## üë©üèΩ‚Äçüè´ Learn More

To learn more about LangChain, OpenAI, Next.js, and the Vercel AI SDK take a look at the following resources:

- [LangChain Documentation](https://js.langchain.com/docs) - learn about LangChain
- [Ollama](https://ollama.ai/) - learn about Ollama features, models, and API
- [Qdrant Documentation](https://qdrant.tech/documentation/) - learn about Qdrant
- [Vercel AI SDK docs](https://sdk.vercel.ai/docs) - learn mode about the Vercel AI SDK
- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API
